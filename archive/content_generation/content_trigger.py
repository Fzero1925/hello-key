#!/usr/bin/env python3
"""
æ–‡ç« ç”Ÿæˆè§¦å‘å™¨ - Content Generation Trigger (Archived)
ä»å®æ—¶åˆ†æä¸­è§¦å‘æ–‡ç« ç”Ÿæˆçš„åŠŸèƒ½æ¨¡å—

æ³¨æ„ï¼šæ­¤æ¨¡å—å·²å½’æ¡£ï¼Œç”¨äºä¿ç•™æ–‡ç« ç”ŸæˆåŠŸèƒ½ã€‚
å®æ—¶è§¦å‘å™¨ç°åœ¨ä¸“æ³¨äºçº¯åˆ†æè¾“å‡ºã€‚
"""

import os
import sys
import json
import asyncio
import subprocess
import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Any
from pathlib import Path
import yaml

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

try:
    from modules.keyword_tools.scoring import make_revenue_range
except ImportError:
    def make_revenue_range(v):
        return {"point": v, "range": f"${v*0.75:.0f}â€“${v*1.25:.0f}/mo"}

from modules.trending.realtime_analyzer import TrendingTopic


class ContentGenerationTrigger:
    """æ–‡ç« ç”Ÿæˆè§¦å‘å™¨ï¼ˆå·²å½’æ¡£ï¼‰"""

    def __init__(self):
        self.logger = self._setup_logging()
        self.data_dir = "data/content_generation"
        self.generation_history = "data/generation_history"

        # åˆ›å»ºå¿…è¦ç›®å½•
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(self.generation_history, exist_ok=True)

        # è§¦å‘æ¡ä»¶é…ç½®
        self.trigger_thresholds = {
            'min_opportunity_score': 70,
            'min_trend_score': 0.75,
            'min_commercial_value': 0.70,
            'min_urgency_score': 0.8,
            'min_search_volume': 10000,
            'max_competition_level': 'Medium-High'
        }

        # é˜²é‡å¤ç”Ÿæˆé…ç½®
        self.cooldown_hours = 6
        self.max_daily_generations = 4

    def _setup_logging(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('data/content_generation.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)

    async def execute_content_generation(self, topic: TrendingTopic) -> Dict[str, Any]:
        """æ‰§è¡Œå†…å®¹ç”Ÿæˆ"""
        self.logger.info(f"ğŸš€ å¼€å§‹ä¸º '{topic.keyword}' ç”Ÿæˆæ–‡ç« ...")

        start_time = datetime.now(timezone.utc)

        try:
            # åˆ¤æ–­æ–‡ç« è§’åº¦
            angle = 'use-case' if any(k in topic.keyword.lower() for k in
                ['outdoor','pet','apartment','garage','wireless','energy']) else 'best'

            # å‡†å¤‡å•ä¸ªå…³é”®è¯çš„lineup
            one_item_lineup = [{
                'keyword': topic.keyword,
                'category': topic.category,
                'angle': angle,
                'trend_score': topic.trend_score,
                'reason': 'Content generation trigger'
            }]

            # ä¿å­˜lineupæ–‡ä»¶
            os.makedirs('data', exist_ok=True)
            with open('data/daily_lineup_latest.json', 'w', encoding='utf-8') as f:
                json.dump(one_item_lineup, f, indent=2, ensure_ascii=False)

            # è°ƒç”¨æ–‡ç« ç”Ÿæˆè„šæœ¬ (éœ€è¦å®é™…çš„è„šæœ¬è·¯å¾„)
            result = subprocess.run([
                'python', 'scripts/workflow_quality_enforcer.py',
                '--count', '1',
            ], capture_output=True, text=True, timeout=600)

            if result.returncode == 0:
                # ç”ŸæˆæˆåŠŸ
                generation_result = {
                    'status': 'success',
                    'keyword': topic.keyword,
                    'category': topic.category,
                    'start_time': start_time.isoformat(),
                    'end_time': datetime.now(timezone.utc).isoformat(),
                    'trigger_reason': getattr(topic, 'business_reasoning', 'Content generation'),
                    'estimated_revenue': getattr(topic, 'estimated_revenue', 'N/A'),
                    'urgency_score': topic.urgency_score,
                    'stdout': result.stdout,
                    'stderr': result.stderr if result.stderr else None
                }

                # è®°å½•åˆ°å†å²
                self._log_generation(generation_result, topic)

                self.logger.info(f"âœ… '{topic.keyword}' æ–‡ç« ç”ŸæˆæˆåŠŸ")

            else:
                # ç”Ÿæˆå¤±è´¥
                generation_result = {
                    'status': 'failed',
                    'keyword': topic.keyword,
                    'error': result.stderr or 'Unknown error',
                    'return_code': result.returncode,
                    'start_time': start_time.isoformat(),
                    'end_time': datetime.now(timezone.utc).isoformat()
                }

                self.logger.error(f"âŒ '{topic.keyword}' æ–‡ç« ç”Ÿæˆå¤±è´¥: {result.stderr}")

        except subprocess.TimeoutExpired:
            generation_result = {
                'status': 'timeout',
                'keyword': topic.keyword,
                'error': 'Generation process timed out after 10 minutes',
                'start_time': start_time.isoformat(),
                'end_time': datetime.now(timezone.utc).isoformat()
            }
            self.logger.error(f"â° '{topic.keyword}' æ–‡ç« ç”Ÿæˆè¶…æ—¶")

        except Exception as e:
            generation_result = {
                'status': 'error',
                'keyword': topic.keyword,
                'error': str(e),
                'start_time': start_time.isoformat(),
                'end_time': datetime.now(timezone.utc).isoformat()
            }
            self.logger.error(f"ğŸ’¥ '{topic.keyword}' ç”Ÿæˆè¿‡ç¨‹å¼‚å¸¸: {e}")

        return generation_result

    def _log_generation(self, result: Dict, topic: TrendingTopic):
        """è®°å½•ç”Ÿæˆå†å²"""
        history_file = f"{self.generation_history}/generation_log.json"

        log_entry = {
            'timestamp': result['end_time'],
            'keyword': topic.keyword,
            'category': topic.category,
            'status': result['status'],
            'trigger_type': 'content_generation',
            'trend_score': topic.trend_score,
            'commercial_value': topic.commercial_value,
            'urgency_score': topic.urgency_score,
            'estimated_revenue': getattr(topic, 'estimated_revenue', 'N/A'),
            'sources': getattr(topic, 'sources', [])
        }

        # è¯»å–ç°æœ‰å†å²
        history = []
        if os.path.exists(history_file):
            try:
                with open(history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            except Exception as e:
                self.logger.error(f"è¯»å–å†å²è®°å½•å¤±è´¥: {e}")

        # æ·»åŠ æ–°è®°å½•
        history.append(log_entry)

        # ä¿æŒæœ€è¿‘100æ¡è®°å½•
        if len(history) > 100:
            history = history[-100:]

        # ä¿å­˜æ›´æ–°çš„å†å²
        try:
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")

    def check_generation_eligibility(self, topic: TrendingTopic) -> Dict[str, Any]:
        """æ£€æŸ¥è¯é¢˜æ˜¯å¦ç¬¦åˆç”Ÿæˆæ¡ä»¶"""
        checks = {
            'trend_score': topic.trend_score >= self.trigger_thresholds['min_trend_score'],
            'commercial_value': topic.commercial_value >= self.trigger_thresholds['min_commercial_value'],
            'urgency_score': topic.urgency_score >= self.trigger_thresholds['min_urgency_score'],
            'search_volume': getattr(topic, 'search_volume_est', 0) >= self.trigger_thresholds['min_search_volume'],
            'competition_ok': self._check_competition_level(getattr(topic, 'competition_level', 'High')),
            'no_recent_generation': not self._check_recent_generation(topic.keyword),
            'under_daily_limit': not self._check_daily_limit()
        }

        passed = sum(checks.values())
        eligible = passed >= 5  # éœ€è¦é€šè¿‡è‡³å°‘5é¡¹æ£€æŸ¥

        return {
            'eligible': eligible,
            'checks_passed': passed,
            'total_checks': len(checks),
            'details': checks,
            'reason': self._get_eligibility_reason(checks) if not eligible else "ç¬¦åˆç”Ÿæˆæ¡ä»¶"
        }

    def _check_competition_level(self, competition: str) -> bool:
        """æ£€æŸ¥ç«äº‰åº¦æ˜¯å¦å¯æ¥å—"""
        competition_levels = {
            'Low': 1, 'Low-Medium': 2, 'Medium': 3,
            'Medium-High': 4, 'High': 5
        }

        current_level = competition_levels.get(competition, 3)
        max_level = competition_levels.get(self.trigger_thresholds['max_competition_level'], 4)

        return current_level <= max_level

    def _check_recent_generation(self, keyword: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ€è¿‘å·²ç”Ÿæˆè¿‡ç›¸ä¼¼å†…å®¹"""
        history_file = f"{self.generation_history}/generation_log.json"

        if not os.path.exists(history_file):
            return False

        try:
            with open(history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)

            cutoff_time = datetime.now(timezone.utc) - timedelta(hours=self.cooldown_hours)

            for record in history[-20:]:
                if record['keyword'].lower() == keyword.lower():
                    gen_time = datetime.fromisoformat(record['timestamp'].replace('Z', '+00:00'))
                    if gen_time > cutoff_time:
                        return True

        except Exception as e:
            self.logger.error(f"âš ï¸ æ£€æŸ¥ç”Ÿæˆå†å²å¤±è´¥: {e}")

        return False

    def _check_daily_limit(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ¯æ—¥ç”Ÿæˆé™é¢"""
        history_file = f"{self.generation_history}/generation_log.json"

        if not os.path.exists(history_file):
            return False

        try:
            with open(history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)

            today = datetime.now(timezone.utc).date()
            today_count = 0

            for record in history[-50:]:
                gen_date = datetime.fromisoformat(record['timestamp'].replace('Z', '+00:00')).date()
                if gen_date == today:
                    today_count += 1

            return today_count >= self.max_daily_generations

        except Exception as e:
            self.logger.error(f"âš ï¸ æ£€æŸ¥æ¯æ—¥é™é¢å¤±è´¥: {e}")
            return False

    def _get_eligibility_reason(self, checks: Dict[str, bool]) -> str:
        """è·å–ä¸ç¬¦åˆç”Ÿæˆæ¡ä»¶çš„åŸå› """
        failed_checks = [key for key, value in checks.items() if not value]

        reason_map = {
            'trend_score': 'è¶‹åŠ¿è¯„åˆ†è¿‡ä½',
            'commercial_value': 'å•†ä¸šä»·å€¼ä¸è¶³',
            'urgency_score': 'ç´§æ€¥åº¦ä¸å¤Ÿ',
            'search_volume': 'æœç´¢é‡åä½',
            'competition_ok': 'ç«äº‰è¿‡äºæ¿€çƒˆ',
            'no_recent_generation': 'æœ€è¿‘å·²ç”Ÿæˆç›¸ä¼¼å†…å®¹',
            'under_daily_limit': 'å·²è¾¾æ¯æ—¥ç”Ÿæˆé™é¢'
        }

        reasons = [reason_map.get(check, check) for check in failed_checks]
        return '; '.join(reasons)


# ä¾¿æ·æ¥å£å‡½æ•°
async def generate_content_for_topic(topic: TrendingTopic) -> Dict[str, Any]:
    """ä¸ºæŒ‡å®šè¯é¢˜ç”Ÿæˆå†…å®¹"""
    trigger = ContentGenerationTrigger()
    eligibility = trigger.check_generation_eligibility(topic)

    if eligibility['eligible']:
        return await trigger.execute_content_generation(topic)
    else:
        return {
            'status': 'not_eligible',
            'keyword': topic.keyword,
            'reason': eligibility['reason'],
            'eligibility_details': eligibility
        }


# æ¼”ç¤ºå’Œæµ‹è¯•
if __name__ == "__main__":
    # æ¼”ç¤ºå†…å®¹ç”ŸæˆåŠŸèƒ½
    print("ğŸ“ æ–‡ç« ç”Ÿæˆè§¦å‘å™¨æ¼”ç¤º")
    print("æ­¤æ¨¡å—å·²å½’æ¡£ï¼Œç”¨äºä¿ç•™æ–‡ç« ç”ŸæˆåŠŸèƒ½")
    print("å®é™…ä½¿ç”¨éœ€è¦é…ç½®å®Œæ•´çš„æ–‡ç« ç”Ÿæˆè„šæœ¬è·¯å¾„")